import nbformat as nbf
from nbformat.v4 import new_notebook, new_markdown_cell, new_code_cell
import os

def load_file_content(filepath):
    """Utility to load content from a file."""
    try:
        with open(filepath, 'r') as f:
            return f.read()
    except FileNotFoundError:
        return f"File not found: {filepath}"

def create_notebook():
    # Load contents
    report_content = load_file_content('remoteok_project/REPORT.md')
    scraper_code = load_file_content('remoteok_project/scripts/scraper.py')
    analysis_code = load_file_content('remoteok_project/scripts/analysis.py')
    
    # Create a new notebook
    nb = new_notebook()

    # --- Section 1: Project Overview and Setup ---
    nb.cells.append(new_markdown_cell(
        "# Remote Job Market Intelligence using Ethical Web Scraping\n\n"
        "**Internship Mini-Project**\n\n"
        "This notebook documents the entire process of collecting, cleaning, analyzing, and visualizing data from the remote job market, specifically using RemoteOK as the source. The project adheres strictly to ethical scraping guidelines.\n\n"
        "## 1. Project Setup and Dependencies\n"
        "The following libraries are required for this project:\n"
        "```bash\n"
        "pip install requests beautifulsoup4 pandas matplotlib seaborn\n"
        "```\n\n"
        "The project structure is organized for clarity and reproducibility:\n"
        "```\n"
        "remoteok_project/\n"
        "├── data/\n"
        "├── scripts/\n"
        "├── visualizations/\n"
        "├── REPORT.md\n"
        "└── remoteok_scraping_project.ipynb (This file)\n"
        "```"
    ))
    
    # --- Section 2: Ethical Web Scraping Implementation ---
    nb.cells.append(new_markdown_cell(
        "## 2. Ethical Web Scraping Implementation\n\n"
        "The core of the data collection is the `RemoteOKScraper` class. It uses the `requests` library to fetch the page and `BeautifulSoup` to parse the job listings. Crucially, it is designed to be ethical by setting a proper User-Agent and respecting the site's `robots.txt` rules (e.g., implementing a crawl delay).\n\n"
        "**NOTE**: Due to the sandbox environment's network limitations and the target site's anti-scraping measures, the live scraping function is included for demonstration but will not be executed in this notebook. We will proceed with the pre-generated mock data for the analysis section, which is a common practice when facing live data access issues."
    ))
    nb.cells.append(new_code_cell(
        "# Scraper Code (scripts/scraper.py)\n"
        f"{scraper_code}"
    ))
    
    # --- Section 3: Data Analysis and Visualization ---
    nb.cells.append(new_markdown_cell(
        "## 3. Data Analysis and Visualization\n\n"
        "The analysis script processes the cleaned data (`remoteok_jobs_cleaned.csv`) to generate key market intelligence insights. We use `pandas` for data manipulation and `matplotlib`/`seaborn` for professional visualizations. The visualizations are saved to the `visualizations/` directory."
    ))
    
    # Adjust the analysis code to run correctly within the notebook environment
    # The data path needs to be adjusted from 'remoteok_project/data/...' to '../data/...'
    # when the notebook is run from the project root.
    analysis_code_adjusted = analysis_code.replace(
        "data_path = 'remoteok_project/data/remoteok_jobs_cleaned.csv'",
        "data_path = './data/remoteok_jobs_cleaned.csv' # Adjusted path for notebook context"
    ).replace(
        'os.makedirs("remoteok_project/visualizations", exist_ok=True)',
        'os.makedirs("./visualizations", exist_ok=True)'
    ).replace(
        "'remoteok_project/visualizations/",
        "'./visualizations/"
    )
    
    nb.cells.append(new_code_cell(
        "# Analysis Code (scripts/analysis.py)\n"
        f"{analysis_code_adjusted}"
    ))
    
    # --- Section 4: Project Report and Conclusion ---
    nb.cells.append(new_markdown_cell(
        "## 4. Project Report and Conclusion\n\n"
        "The full findings, including the executive summary, methodology, comparative insights, and limitations, are detailed in the accompanying report. The visualizations generated by the code above are available in the `visualizations/` folder.\n\n"
        "### Excerpt from REPORT.md\n"
        "```markdown\n"
        f"{report_content}\n"
        "```"
    ))

    # Save the notebook
    notebook_path = 'remoteok_project/remoteok_scraping_project.ipynb'
    with open(notebook_path, 'w', encoding='utf-8') as f:
        nbf.write(nb, f)
    
    print(f"IPython Notebook created successfully at {notebook_path}")

if __name__ == "__main__":
    create_notebook()
